{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "383e1539-0b88-43bc-9ff9-eb3db3c8dec0",
   "metadata": {},
   "source": [
    "# Single-peak mesh fitting\n",
    "\n",
    "Runs a parallelized peak fitting routine on xrd maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38aaa13c-6a01-4712-b8b5-0b22a8555335",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary libaries\n",
    "%matplotlib widget\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import h5py as h5\n",
    "import matplotlib.pyplot as plt\n",
    "#To import DanMAX from the folder above:\n",
    "sys.path.append('../')\n",
    "import DanMAX as DM\n",
    "    \n",
    "style = DM.darkMode(style_dic={'size':'large'})\n",
    "\n",
    "def apply_roi(maps, bkg_roi, peak_roi,local_bkg=True):\n",
    "    \"\"\"apply a region of interest to diffraction data. Subtract local\n",
    "    background of specified.\"\"\"\n",
    "    if local_bkg:\n",
    "        xrd_map = (maps['xrd_map'][:,:,peak_roi].transpose(2,0,1) -np.mean(maps['xrd_map'][:,:,bkg_roi],axis=2)).transpose(1,2,0)\n",
    "    else:\n",
    "        xrd_map = maps['xrd_map'][:,:,peak_roi]\n",
    "    tth = maps['x_xrd'][peak_roi]\n",
    "    return xrd_map, tth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c49415a-61ab-4f91-964a-0fa515f772a1",
   "metadata": {},
   "source": [
    "### Load the data\n",
    "Set the group and sample from the sample database (see *Sample_list.ipynb*)  \n",
    "or use a list of scan numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fd0d9b-9781-4bcf-bb97-7811d8f8fd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define scan location:\n",
    "#Note that scans must be a list!\n",
    "\n",
    "samples_database = False\n",
    "if samples_database: # To use samples_database, and to do bulk processing, use the \"Samples_list\" notebook\n",
    "    groups = DM.getProposalScans()\n",
    "    group = 'group'\n",
    "    sample = 'sample'\n",
    "    scans = groups[group][sample]\n",
    "    title = f'{group}: {sample}'\n",
    "else:\n",
    "    scans = [200]\n",
    "    title = DM.getScan_id(DM.findScan(scans[0]))\n",
    "proposal,visit=DM.getCurrentProposal()\n",
    " \n",
    "#Select ranges to load (in the unit the data were integrated with)\n",
    "#useful for reducing the size of large datasets\n",
    "xrd_range = None # (lower,upper) or None\n",
    "azi_range = None # (lower,upper) or None\n",
    "\n",
    "#Load data\n",
    "maps = DM.mapping.stitchScans(scans,XRF=False,proposal=proposal,visit=visit,xrd_range=xrd_range,azi_range=azi_range)\n",
    "#Apply I0 correction\n",
    "maps['xrd_map'] = (maps['xrd_map'].transpose(2,0,1)/ maps['I0_map']).transpose(1,2,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a233b7-a278-4b86-bd60-85d3f2b5718d",
   "metadata": {},
   "source": [
    "### Define a mask and ROI\n",
    "Use the interactive mask to select a region of interest with left/right mouse click in the upper plot.  \n",
    "Select a mask threshold with left/right mouse click in the histogram to the right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2162ae1-2919-4da1-83ff-7f0cc2bd1043",
   "metadata": {},
   "outputs": [],
   "source": [
    "imask = DM.InteractiveMask(maps['xrd_map'],reduction_mode='std')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be8acf0-12c1-47bc-a8e7-a7d84a513501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the current mask(s) from the interactive tool\n",
    "mask = imask.getMask()\n",
    "bool_mask = mask.astype(bool)\n",
    "nan_mask = imask.getNanMask()\n",
    "# get the lower/upper threshold\n",
    "lower, upper = sorted(imask.getRoiThreshold())\n",
    "\n",
    "########################\n",
    "apply_local_bkg = False\n",
    "num_of_bgr_pts = 5\n",
    "########################\n",
    "# set the number of points to use as background\n",
    "peak_roi = np.s_[lower+num_of_bgr_pts:upper-num_of_bgr_pts]\n",
    "bkg_roi = np.r_[lower:lower+num_of_bgr_pts,upper-num_of_bgr_pts:upper] # indexes from background\n",
    "xrd_map,tth = apply_roi(maps,bkg_roi,peak_roi,local_bkg=apply_local_bkg)\n",
    "\n",
    "# calculate the mean diffraction signal for the selected mask and ROI\n",
    "y_mean = np.nanmean(xrd_map[bool_mask],axis=0)\n",
    "\n",
    "# plot the mask and selected ROI\n",
    "fig, [ax0,ax1] = plt.subplots(1,2)\n",
    "fig.suptitle(title)\n",
    "ax0.set_title('mask')\n",
    "ax0.imshow(mask)\n",
    "ax0.set_xticks([])\n",
    "ax0.set_yticks([])\n",
    "\n",
    "ax1.set_title('roi')\n",
    "ax1.plot(tth,y_mean)\n",
    "ax1.plot(tth,y_mean)\n",
    "\n",
    "ax1.axvspan(tth[0],tth[num_of_bgr_pts],color='#AAAAAA44')\n",
    "ax1.axvspan(tth[-num_of_bgr_pts],tth[-1],color='#AAAAAA44')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cfab38-437f-426b-8112-bb9c806e3fef",
   "metadata": {},
   "source": [
    "## Run mesh peak fit.\n",
    "Run the parallelized peak fitting and show a short summary of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e092db69-fc41-4a30-b1cf-e113569b3749",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitmap = DM.fitting.fitMesh(DM.fitting.pVPeakFit,  # peak fit function\n",
    "                            tth,                   # x-values\n",
    "                            xrd_map,                  # list of list of y-values\n",
    "                            mask,                  # mask of px to fit (int mask)\n",
    "                            verbose=True,          # print output\n",
    "                            sequential=True,       # toggle sequential mode\n",
    "                            fun_kwargs={}          # peak function keyword arguments\n",
    "                           )\n",
    "\n",
    "print('\\n',f'Fitting complete - {np.sum(mask):d} pixels fitted\\n')\n",
    "# parse the fitting results to a more meaningfull\n",
    "# dictionary of results, based on the scheme of\n",
    "# the parsing function\n",
    "parsed_params,names = DM.fitting.parseFitMesh(DM.fitting.parsePVPeakFit, # parsing function\n",
    "                                           fitmap,                    # results from the mesh fit\n",
    "                                          )\n",
    "results = {name:parsed_params[:,:,i] for i,name in enumerate(names)}\n",
    "\n",
    "# print a short summary of the results\n",
    "print(f\"{' parameter':<15}{'mean':>15}{'std':>15}\\n\",''.join(['â€¾']*45))\n",
    "for key,val in results.items():\n",
    "    print(f' {key:<15} {np.nanmean(val[bool_mask]):14.4f} {np.nanstd(val[bool_mask]):14.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d32044-4490-4aa7-8032-f0c5e76495e4",
   "metadata": {},
   "source": [
    "### plot the results as maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ab925d-b09f-45c2-b39f-7c1dd9e8cdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of columns for the figure\n",
    "cols = 4\n",
    "\n",
    "# initialize figure\n",
    "rows = int(len(results)/cols) + (len(results)%cols!=0)\n",
    "fig, axes = plt.subplots(rows,cols,sharex=True,sharey=True)\n",
    "fig.suptitle('Results')\n",
    "axes = axes.flatten()\n",
    "i=0\n",
    "for name,result in results.items():\n",
    "    ax = axes[i]\n",
    "    ax.set_title(name)\n",
    "    ax.imshow(result*nan_mask)\n",
    "    i +=1\n",
    "    \n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "\n",
    "# delete surplus plots\n",
    "for i in range(1,cols*rows-len(results)+1):\n",
    "    fig.delaxes(axes[-i])\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b66404-e100-4976-9b1b-cdd6d29c2917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculated peak values (without background)\n",
    "y_calc = DM.fitting.pVPeakMesh(tth,\n",
    "                                results['position'],\n",
    "                                results['integral'],\n",
    "                                results['FWHM'],\n",
    "                                results['eta'],\n",
    "                               )\n",
    "# calculated background\n",
    "bgr_coeff = np.array([results[key] for key in sorted(results.keys()) if 'bgr_' in key])\n",
    "bgr =  np.polynomial.chebyshev.chebval(tth,bgr_coeff)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa111b0-a315-457c-b8f1-c0fdb0d5ef97",
   "metadata": {},
   "source": [
    "## Save the results\n",
    "Change the `save_results` flag to save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873759e8-c8f7-4233-801e-90e7912ce9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "save_results = False\n",
    "#####################\n",
    "\n",
    "if save_results:\n",
    "    if samples_database:\n",
    "        save_dst = DM.findScan(scans[0]).split('raw/')[0]+f'process/mesh_fit/{group}/{sample}'\n",
    "    else:\n",
    "        save_dst = DM.findScan(scans[0]).replace('/raw','/process/mesh_fit')\n",
    "    \n",
    "    if not os.path.isdir(os.path.dirname(save_dst)):\n",
    "        os.makedirs(os.path.dirname(save_dst))\n",
    "    \n",
    "    h5.get_config().track_order=True\n",
    "    with h5.File(save_dst,'w') as f:\n",
    "        f.create_dataset('x_map',data=maps['x_map'])\n",
    "        f.create_dataset('y_map',data=maps['y_map'])\n",
    "        f.create_dataset('mask',data=mask)\n",
    "        f.create_dataset('obs',data=xrd_map)\n",
    "        f.create_dataset('calc',data=y_calc+bgr)\n",
    "        f.create_dataset('diff',data=xrd_map-(y_calc+bgr))\n",
    "        f.create_dataset('bgr',data=bgr)\n",
    "        for name, result in results.items():\n",
    "            f.create_dataset(name,data=result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HDF5 / Standard Analysis / GPU",
   "language": "python",
   "name": "maxiv-jup-kernel-hdf5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
