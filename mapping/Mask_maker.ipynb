{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6382e95d-0a4c-4683-90aa-4e6d6c19cece",
   "metadata": {},
   "source": [
    "#  Making masks for samples based on XRF signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23ed97ba-ff15-45f8-9c91-2987d72bca8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary libaries\n",
    "\n",
    "%matplotlib widget\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import scipy.ndimage as ndimage\n",
    "#To import DanMAX from the folder above:\n",
    "sys.path.append('../')\n",
    "import DanMAX as DM\n",
    "from lib.xrf_pyMCA_fit import xrfBatch\n",
    "style = DM.darkMode(style_dic={'figure.figsize':'large'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124e7002-c1f5-4408-92ee-0b045e9df847",
   "metadata": {},
   "source": [
    "## Define the samples and all the groups\n",
    "\n",
    "could also be ecpanded with more information about each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd67a0f3-a1f7-49d6-9dc5-6b44f7aaecb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = DM.getProposalScans()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4df70c3b-6021-402d-8f0a-d3d55c90b105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3)\n"
     ]
    }
   ],
   "source": [
    "#Define the location where the XRF fits are saved within the XRF file\n",
    "xrf_h5_fit_path = 'xrf_fits/xrf_fit/results/parameters/Ca_K'\n",
    "proposal, visit = DM.getCurrentProposal()\n",
    "bin_struct = ndimage.iterate_structure(ndimage.generate_binary_structure(2,1),1)\n",
    "for group in groups:\n",
    "    new_file = True\n",
    "    for sample in groups[group]:\n",
    "        scans = groups[group][sample]\n",
    "        xrf_fit_dir, xrf_fit_file = DM.mapping.getXRFFitFilename(scans,proposal=proposal,visit=visit)\n",
    "        xrf_fits_filename = f'{xrf_fit_dir}/elements/{xrf_fit_file}.h5' \n",
    "        mask_foldername =  '/'.join(xrf_fit_dir.split('/')[0:-3]).replace('xrf_fit','mask')\n",
    "\n",
    "        if not os.path.isdir(mask_foldername):\n",
    "            os.makedirs(mask_foldername)\n",
    "            os.chmod(mask_foldername, 0o770)\n",
    "\n",
    "        \n",
    "        with h5py.File(xrf_fits_filename, 'r' ) as xrf_file:\n",
    "            ca = xrf_file[xrf_h5_fit_path][:]\n",
    "        binary_image = ndimage.binary_erosion(ndimage.binary_dilation(ca>200,bin_struct),bin_struct)\n",
    "        labels, n_features = ndimage.label(binary_image)\n",
    "        size = ndimage.sum(binary_image,labels,range(n_features+1))\n",
    "        \n",
    "        mask = size[labels] > 300\n",
    "        mask_file = os.path.join(mask_foldername,f'{group}.h5')\n",
    "        if new_file:\n",
    "            new_file = False\n",
    "            with h5py.File(mask_file,'w') as mf:\n",
    "                mf.create_dataset(f'mask/{sample}', data = mask)\n",
    "        else:\n",
    "            with h5py.File(mask_file,'a') as mf:\n",
    "                mf.create_dataset(f'mask/{sample}', data = mask)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HDF5 / Standard Analysis / GPU",
   "language": "python",
   "name": "maxiv-jup-kernel-hdf5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
