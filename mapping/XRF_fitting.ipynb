{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "260996d2-98cb-402f-8541-1bcaf35ce386",
   "metadata": {},
   "source": [
    "# Fitting XRF maps\n",
    "\n",
    "This notebook will create and displays fits of mapping scans.\n",
    "The scans can either be single scans, or a set of scans taken across a sample to reduce the sample files.\n",
    "All the scans should be from the same sample and same region, with a small overlap in motor positions.\n",
    "(Basically a set of scans created by the mapping tool for a single region)\n",
    "\n",
    "*Remember to create the calibration and configuration files using pymca!\n",
    "This script will not run without them!!*\n",
    "\n",
    "#### Note that the scans *must* be given in list form, even if it is a single scan!\n",
    "\n",
    "### Scans database.\n",
    "\n",
    "For bulk processing of multiple scans, you can save a list of scans forming a single map in the sample database.\n",
    "This is done using the notebook ``Samples_list.ipynb''\n",
    "\n",
    "These scans can also be loaded for individual fitting, bulk fitting in the bottom of the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6966cc4c-8ba5-4403-988a-5e7865af4a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary libaries\n",
    "\n",
    "%matplotlib widget\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "#To import DanMAX from the folder above:\n",
    "sys.path.append('../')\n",
    "import DanMAX as DM\n",
    "from lib.xrf_pyMCA_fit import xrfBatch\n",
    "style = DM.darkMode(style_dic={'figure.figsize':'large'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8be0ab1-16b6-436f-9695-a2f934f701c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select scans to fit, must be a list!!!\n",
    "#Define parameters to find the data\n",
    "\n",
    "proposal,visit = DM.getCurrentProposal() #Default will be collected from the current path, you can set others, if you wish to use data from a previous beamtime\n",
    "proposal_type, beamline = DM.getCurrentProposalType()\n",
    "\n",
    "samples_database = True\n",
    "if samples_database: # To use samples_database, and to do bulk processing, use the \"Samples_list\" notebook\n",
    "    groups = DM.getProposalScans(proposal_type=proposal_type,beamline=beamline,proposal=proposal,visit=visit)\n",
    "    group = 'group'\n",
    "    sample = 'sample'\n",
    "    scans = groups[group][sample]\n",
    "else:\n",
    "    scans = [XXXX]\n",
    "\n",
    "#Sessionpath will tell the fitter which proposal and visit it should read data from\n",
    "#This will also be used to find where to store fitted data\n",
    "sessionpath = f'/data/{proposal_type}/{beamline}/{proposal}/{visit}/' #Default will be f'/data/visitors/danmax/{proposal}/{visit}/'\n",
    "\n",
    "#Calibration and configuration files must be made in pyfai prior to fitting:\n",
    "calib_file  = f'{sessionpath}process/pymca_calib.calib'\n",
    "config_file = f'{sessionpath}process/pymca_config.cfg' \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#The following code sets up the fitter. \n",
    "#You can change if you want different things, but it should be good enough!\n",
    "channel     = 0 #Default is 0\n",
    "detector    = 'xpress3-dtc-2d' #Default is falconx\n",
    "\n",
    "\n",
    "#Define which files output to save\n",
    "make_elements_h5     = True\n",
    "make_elements_tif    = False\n",
    "make_pymca_h5        = True\n",
    "make_spectrum_fit_h5 = True\n",
    "return_fit_filename  = False\n",
    "\n",
    "#Define the XRF batch fitter\n",
    "fits= xrfBatch(session_path= sessionpath,\n",
    "               scan_list=scans,\n",
    "               config_file=config_file,\n",
    "               calib_file=calib_file,\n",
    "               channel=channel,\n",
    "               detector=detector,\n",
    "               proposal_type=proposal_type,\n",
    "               beamline=beamline,\n",
    "               proposal=proposal,\n",
    "               visit=visit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52ea127-c048-481b-83a7-289a7fd26182",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the the data and stitch them if there are multiple scans\n",
    "fits.readData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eaef6a4-2983-4164-9f26-6ed8c37b7977",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the data and the average spectrum\n",
    "fits.writePymcafile()\n",
    "fits.fitElementsToFile(make_elements_h5,make_elements_tif,return_fit_filename)\n",
    "fits.fitAvgSpectrumToFile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073de1e9-5f9f-41ba-8d74-5388c157897c",
   "metadata": {},
   "source": [
    "## Showing the fitted maps\n",
    "\n",
    "The following code snippits takes the fitted maps from above and plots them as images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5783d5ff-9dc4-470b-aff1-ae105db6a4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the information needed to plot the fits\n",
    "\n",
    "#Define the h5 file containing the fits. Default is from the file just fitted above.\n",
    "#If another file is neededset it here\n",
    "fits_filename = f'{fits.out_dir_elements}{fits.elem_file_name}.h5'\n",
    "\n",
    "#Define which maps to plot, the lists give the lower and upper limit.\n",
    "#Set limits to \"None\" for default value\n",
    "maps_to_show = {'Ca_K':[None, None],\n",
    "               'Sr_K': [None, None],\n",
    "               'Zn_K': [None, None],\n",
    "                }\n",
    "\n",
    "# Set the number of columns for the figure\n",
    "cols = 3 \n",
    "rows = int(len(maps_to_show)/cols) + (len(maps_to_show)%cols!=0)\n",
    "\n",
    "#Set the base path in the h5 fit file to the fit maps\n",
    "h5_fit_path = 'xrf_fits/xrf_fit/results/parameters/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a87f8cb-2c8a-44c0-a43f-72543e634394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize subplots with shared x- and y-axes\n",
    "fig,axs = plt.subplots(rows,cols,sharex=True,sharey=True)\n",
    "fig.tight_layout()\n",
    "axs = axs.flatten() # flatten the axes list to make it easier to index\n",
    "\n",
    "#Open file containing fitted maps\n",
    "with h5py.File(fits_filename,'r') as fit_file: \n",
    "    for ii,key in enumerate(maps_to_show.keys()):\n",
    "        #Load element specific data\n",
    "        element = fit_file[f'{h5_fit_path}{key}']\n",
    "        ax = axs[ii]\n",
    "        ax.set_title(key)\n",
    "        ax.set_axis_off()\n",
    "        ax.set_aspect('equal')\n",
    "        \n",
    "        #Plot the data with pcolmesh\n",
    "        if 'fits' in locals():\n",
    "            ax.pcolormesh(fits.x.reshape(element.shape),\n",
    "                          fits.y.reshape(element.shape),\n",
    "                          element,\n",
    "                          vmin=maps_to_show[key][0],\n",
    "                          vmax=maps_to_show[key][1],\n",
    "                          shading='nearest')\n",
    "            \n",
    "        else:\n",
    "            #Use imshow if the \"fits\" variable has been unloaded.\n",
    "            ax.imshow(element,\n",
    "                     vmin=maps_to_show[key][0],\n",
    "                     vmax=maps_to_show[key][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214952da-8411-4ac9-84f3-f354225f2a40",
   "metadata": {},
   "source": [
    "## Bulk fitting \n",
    "\n",
    "Fitting all scans in the database.\n",
    "to make the sample database, enter your scans in \"Samples_list.ipynb\"\n",
    "\n",
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8280624a-bf12-44f1-a5e6-de5b499e5b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define parameters to find the data\n",
    "proposal,visit = DM.getCurrentProposal() #Default will be collected from the current path, you can set others, if you wish to use data from a previous beamtime\n",
    "proposal_type, beamline = DM.getCurrentProposalType()\n",
    "\n",
    "#Sessionpath will tell the fitter which proposal and visit it should read data from\n",
    "#This will also be used to find where to store fitted data\n",
    "sessionpath = f'/data/{proposal_type}/{beamline}/{proposal}/{visit}/' #Default will be f'/data/visitors/danmax/{proposal}/{visit}/'\n",
    "\n",
    "#Calibration and configuration files must be made in pyfai prior to fitting:\n",
    "calib_file  = f'{sessionpath}process/pymca_calib.calib'\n",
    "config_file = f'{sessionpath}process/pymca_config.cfg' \n",
    "\n",
    "#The following code sets up the fitter. \n",
    "#You can change if you want different things, but it should be good enough!\n",
    "channel     = 0 #Default is 0\n",
    "detector    = 'xpress3-dtc-2d' #Default is falconx\n",
    "\n",
    "#Define which files output to save\n",
    "make_elements_h5     = True\n",
    "make_elements_tif    = False\n",
    "make_pymca_h5        = True\n",
    "make_spectrum_fit_h5 = True\n",
    "return_fit_filename  = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58134b6b-af8e-404f-8891-f2dbbdbedf9c",
   "metadata": {},
   "source": [
    "### Bulk fitting.\n",
    "\n",
    "To run fits, change \"if False\" to \"if True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d553cb5-9954-4402-907d-3b0ae6709923",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import time\n",
    "if False:\n",
    "    groups = DM.getProposalScans(proposal_type=proposal_type,beamline=beamline,proposal=proposal,visit=visit)\n",
    "    for group in groups:\n",
    "        print(f'{datetime.fromtimestamp(np.round(time.time()))} -- fitting group {group}')\n",
    "        for sample in groups[group]:\n",
    "            print(f'fitting sample {sample}')\n",
    "            scans = groups[group][sample]\n",
    "                \n",
    "            #Define the XRF batch fitter\n",
    "            fits= xrfBatch(session_path= sessionpath,\n",
    "                           scan_list=scans,\n",
    "                           config_file=config_file,\n",
    "                           calib_file=calib_file,\n",
    "                           channel=channel,\n",
    "                           detector=detector,\n",
    "                           proposal_type=proposal_type,\n",
    "                           beamline=beamline,\n",
    "                           proposal=proposal,\n",
    "                           visit=visit)\n",
    "            fits.readData()\n",
    "            #Fit the data and the average spectrum\n",
    "            fits.writePymcafile()\n",
    "            fits.fitElementsToFile(make_elements_h5,make_elements_tif,return_fit_filename)\n",
    "            fits.fitAvgSpectrumToFile()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HDF5 / Simple Analysis / GPU",
   "language": "python",
   "name": "maxiv-jhub-hpc-kernel-hdf5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
