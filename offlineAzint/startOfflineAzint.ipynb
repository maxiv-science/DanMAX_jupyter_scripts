{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92ab01b4-2db3-4ff1-b28c-4bb897256c72",
   "metadata": {},
   "source": [
    "# Setup and start offline azimuthal pipeline\n",
    "\n",
    "This notebook will read an existing azint file and extract the integration settings. \n",
    "These settings will be saved in a file: ```azint_config.py``` that can subsequently be edited with your favorite text editor to change the integration parameters.  \n",
    "\n",
    "The only input required in this notebook is the scan number of an integrated file that will serve as a template for the integration configurations.  \n",
    "\n",
    "The offline Azint integration pipeline itself is run in a terminal, details on that can be found in the last cell [**last cell**](#instructions) in this notebook.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc2fd3d-8f17-491e-a3b6-23e109226581",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import DanMAX as DM\n",
    "import h5py\n",
    "import datetime\n",
    "print('Current proposal and visit:')\n",
    "print(os.getcwd().split('scripts')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d2b390-d17d-467d-b69a-ca2c3a01d03d",
   "metadata": {},
   "source": [
    "#### Generate integration configurations using a previously integrated scan as template  \n",
    "Specify the scan numbers of the scans you wish to integrate.  \n",
    "Specify a template scan number that is used for generating the configuration file. If None, use the first scan in ths scan list.\n",
    "\n",
    "Pro tip:  \n",
    "Use  \n",
    "`scans = [int(DM.getScan_id(scan).split('-')[-1]) for scan in DM.findAllScans(scan_type='timescan')]`  \n",
    "to get a list of all *timescan* scan numbers in the current proposal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da8ea65-401c-4352-aaf2-997a61a7a6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specification of scans to be integrated [list of int] (do not use zero-padding)\n",
    "scans = range(firstScan, lastScan+1) # Specified as a range, remeber to end with lastScan+1\n",
    "#scans = [scan1, scan2, scanN] # Manually specified list - a single scan can be specified, but has to be of type list, i.e. with '[scan]'\n",
    "\n",
    "template_scan = None\n",
    "\n",
    "# if no template scan is specified, use the first scan in the list\n",
    "if template_scan == None:\n",
    "    template_scan = scans[0]\n",
    "\n",
    "# Find the file path from the scan number \n",
    "# alternatively insert path for the .h5 file - TIP: Use tap for auto-complete\n",
    "#fname = '/data/visitors/danmax/20230160/2023101208/raw/SAMPLE/scan-XXXX.h5'    \n",
    "fname = DM.findScan(template_scan)\n",
    "\n",
    "# get the azimuthally integrated filename from master file name\n",
    "aname = DM.getAzintFname(fname)\n",
    "\n",
    "# get the path to the poni file (not supported via DanMAX library)\n",
    "poni_file = h5py.File(aname)['entry/azint/input/poni_file'].attrs['filename']\n",
    "\n",
    "# read the integrated data and get number of radial bins\n",
    "data, meta = DM.getAzintData(aname, get_meta = True)\n",
    "if type(data['q']) != type(None):\n",
    "    unit = 'q'\n",
    "    radial_bins = data.get('q').shape[0]\n",
    "else:\n",
    "    unit = '2th'\n",
    "    radial_bins = data.get('tth').shape[0]\n",
    "\n",
    "# generate the config file text\n",
    "myConfig = f\"\"\"\n",
    "# This file was generated on {datetime.datetime.now().strftime('%c')} using\n",
    "# {aname} \n",
    "# as a template\n",
    "\n",
    "# path to poni file [string]\n",
    "poni_file = f'{poni_file}'\n",
    "\n",
    "# path to mask file in npy format [string]\n",
    "mask_file = f'{meta.get('input').get('mask_file').decode()}'\n",
    "\n",
    "# settings used in the integration\n",
    "user_config = {{'poni': poni_file, # do not change this line\n",
    "               'mask': mask_file, # do not change this line\n",
    "               'radial_bins': {radial_bins}, # number of radial bins [int]\n",
    "               'azimuth_bins': {data.get('azi_edge')}, # number of azimuthal bins (or list specifying the azimuthal bins)\n",
    "               'n_splitting': {meta.get('input').get('n_splitting')}, # pixel splitting - number of subdivisions [int[]]\n",
    "               'error_model': {meta.get('error_model')}, # Error model: use 'None' or 'poisson' [str]\n",
    "               'polarization_factor': {meta.get('input').get('polarization_factor')}, # Polarization factor - use 0.999997 [float]\n",
    "               'unit': '{unit}' # Radial unit: use either 'q' or '2th' [str]\n",
    "               }} \n",
    "\n",
    "# Specification of scans to be integrated [list of int]\n",
    "scans = {list(scans)}\n",
    "#scans = range(firstScan, lastScan+1) # Specified as a range, remeber to end with lastScan+1\n",
    "#scans = [scan1, scan2, scanN] # Manually specified list\n",
    "\"\"\"\n",
    "\n",
    "# write to file in **/scripts/offlineAzint/azint_config.py\n",
    "with open('offline_azint_config.py','w') as config_file:\n",
    "    config_file.write(myConfig.strip())\n",
    "\n",
    "print(f'The configuration file has been saved in:\\n{os.path.join(os.getcwd(),\"offline_azint_config.py\")}\\n')\n",
    "print('Open this file and edit it to set all integration parameters.')\n",
    "print('Remeber to edit the scan numbers to be integrated!\\n\\n')\n",
    "print('The content of configuration file is show below:')\n",
    "print(80*'-')\n",
    "print(myConfig.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4cd776-dfad-4bcc-aff4-02414dd589ab",
   "metadata": {},
   "source": [
    "## How to use the offline azint integration pipeline <a id='instructions'></a>\n",
    "\n",
    "The offline integration pipeline can unfortunately not be run in a notebook but has to be run in a terminal via `jupyterhub.maxiv.lu.se`:\n",
    "Open a terminal using the **+** icon in the upper left corner\n",
    "In the Launcher page select **Terminal** under **Other**\n",
    "In the terminal run the following command: `source activate hdf5-kernel-environment` to activate the correct environment\n",
    "The terminal should now show `(hdf5-kernel-environment)` in front of your user name.\n",
    "\n",
    "Navigate to the offlineAzint folder (where this notebook is located): `cd /data/visitors/danmax/PROPOSAL/VISIT/scripts/offlineAzint`\n",
    "\n",
    "In this folder you should have the following files:\n",
    "\n",
    "<table><tr><th>File <th><th>Description <tr><tr>\n",
    "<tr><td><tt>startOfflineAzint.ipynb</tt> <td><td> This notebook. <tr><tr>\n",
    "<tr><td><tt>offline_azint_config.py</tt> <td><td> Configuration file created by this notebook. <br> This file is read by the pipeline. <tr><tr>\n",
    "<tr><td><tt>offline_azint_config_DEFAULT.py</tt> <td><td> A default configuration file for manual editing <br> Make a cope of this file before editing. <br> The new file must be called <tt>'azint_config.py'</tt> <tr><tr>\n",
    "<tr><td><tt>start_offline_pipeline_DanMAX.py</tt> <td><td> This python script is used to start the pipeline <br> DO NOT EDIT THIS FILE! <tr><tr>\n",
    "<tr><td><tt>pipeline.py</tt> <td><td> This is the python script containg the pipeline program <br> DO NOT EDIT THIS FILE! <tr><tr>\n",
    "<tr><td><tt>danmax-pilatus.yaml</tt> <td><td> A settings file for the Pilatus <br> DO NOT EDIT THIS FILE! <tr><tr>\n",
    "<table>\n",
    "\n",
    "After running this notebook your `offline_azint_config.py` has been updated based on the integration parameters in the choosen file. By editing `offline_azint_config.py` you can change the integration parameters.\n",
    "\n",
    "If you want to set up the integration completely from scratch you can make a copy of `offline_azint_config_DEFAULT.py` to `offline_azint_config.py` and edit it to your preference. In this case: Don't forget to specify which scans you want to integrate!\n",
    "    \n",
    "The integration is started by `python start_offline_pipeline_danmax.py` a will show provide progress bars during the integration.\n",
    "    \n",
    "#### HPC\n",
    "It is possible to run the integration using the offline HPC for extra speed. Instructions should be the same as here... \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92e1e9d-9780-419c-b414-d8554c221054",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HDF5 / Simple Analysis / GPU",
   "language": "python",
   "name": "maxiv-jhub-docker-kernel-hdf5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
