{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6ab2933-8c48-4e7d-832a-a104ce7c7a71",
   "metadata": {},
   "source": [
    "# Find noisy and 'oversensitive' pixels\n",
    "\n",
    "This notebook can be used to detect noisy or oversensitive pixels on the area detector. \n",
    "It uses a background measurement of either air or an amorphous sample collected with a timescan - preferably with many exposures.\n",
    "\n",
    "#### __Use at your own risk:__ _This method is not using strignet statistics, nor has not been validated with different energies, exposure times, number of frames etc._ \n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>These parameter values seems to work:</b><br>\n",
    "<tt>filter_value</tt> = 5 <br>\n",
    "<tt>n_sigma</tt> = 2 <br>\n",
    "<tt>cut_off_percent</tt> = 0.1 <br>\n",
    "<tt>neighbour_intensity_ratio</tt> = 1.1<br><br>\n",
    "<b>For masking based on geometry, these parameter values seems to work:</b><br> \n",
    "<tt>grow_edge_by</tt> = 2<br>\n",
    "<tt>mask_edge_by</tt> = 2<br>  \n",
    "<tt>grow_cdte_gap_by</tt> = 1<br>\n",
    "<tt>maskReadout</tt> = True<br>\n",
    "<tt>grow_readout_by</tt> = 1<br>\n",
    "</div>\n",
    "\n",
    "The following algorithm is applied:\n",
    "1) Calculate the average image (`avg_img`) and plot it to check that the data is sensible for this purpose: it should not have any sharp features!\n",
    "2) \n",
    "    a) Filtering of data to remove alpha bombs: This is done by comparing a pixel values to the average count in the pixel (from `avg_img`). If it is more than `filter_value` times the average it is considered an outlier and is replaced with the average value (in order not to skew the statistics in the next step!).<br>\n",
    "    b) Calculation of a mask based on the pixel statistics. All pixels in all exposures are compared to the average value +/- `n_sigma` times the estimated deviation (that is the square root of the average value). The number of exposures where the count is outide this range is summed and compared to `cut_off_percent` times number of exposures. If the number of values outside the range is over this threshold it will be masked.<br>\n",
    "    c) Calculation of the standard deviation (using `np.std` method) divided by the average image (for diagnostic purposes).\n",
    "3) Plot the logarithm of the average image (`avg_img`), the mask (`mask`) and the standard deviation/average image. The plots are used for diagnostic purposes:<br>\n",
    "    a) Checking that pixels standing out in the average image are indeed masked by comparing the left and middle images.<br>\n",
    "    b) Checking that alpha bomb filtering worked well in right image. If the threshold was correct no high values should be visible.\n",
    "4) Mask 'oversensitive' that have higher intensites than their neighbours. Here a map of the average neighbouring values are calculated using a 3x3 kernel (with 1/8 in the perimiter and 0 in the central position) over the average image. The average map is then compared to the average neighbour map. If the value of a pixel is higher than the value of `neighbour_intensity_ratio` it is masked. The resulting map can be checkked in the plots.\n",
    "5) It is possible to investigate the behaviour of a single pixel by inputting the coordinates `px_x, px_y`. The resulting plot shows the number of counts in the series of exposures and the selected 'sigma' range.\n",
    "6) Mask out additional pixels based on geometry (edges, inter-ASIC lines etc) - similar to _MaskTool_\n",
    "7) Save an `.npy` mask to be used for integration - remember the beam-stop is not masked in this tool!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10406a50-de2d-40ea-815f-fc4f5a1d5681",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Load and display avarage data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d07c66c1-b3c6-41aa-b9e0-4c4cef9aa2f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file contains 301 images.\n",
      "The maximum count in a single frames is 5166.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cb9300b84d742248b8186b77fa470ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File loaded and averaged in 4.0 s.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#fname = '/data/visitors/danmax/20210940/2022042008/raw/Empty_200422_FS_SDD177/scan-1452.h5'\n",
    "fname = '/data/visitors/danmax/20220402/2022101908/raw/glass_slide/scan-3804.h5'\n",
    "\n",
    "plot_average = True\n",
    "#------------------------------------------------------------------------\n",
    "\n",
    "%matplotlib widget\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path\n",
    "import time\n",
    "from ipywidgets import IntProgress\n",
    "\n",
    "start = time.perf_counter()\n",
    "fh = h5py.File(fname, 'r')\n",
    "\n",
    "path, f = os.path.split(fname)\n",
    "\n",
    "scanCmd = fh['entry/title'][()].decode('utf-8').split()\n",
    "if plot_average:   \n",
    "    images_h5 = fh['/entry/instrument/pilatus/data']\n",
    "    images = np.copy(images_h5)\n",
    "    avg_img = np.mean(images, axis=0)\n",
    "    \n",
    "    print(f'The file contains {images.shape[0]} images.')\n",
    "    print(f'The maximum count in a single frames is {np.max(images)}.')\n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.imshow(np.log(avg_img+3), interpolation='Nearest')\n",
    "    plt.title('log(average intensity)')\n",
    "    print(f'File loaded and averaged in {time.perf_counter()-start:.1f} s.\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed5a118-e86f-472c-8f59-089dd8340f3c",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Filter data and calculate mask based on pixel data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c465c75-ba32-49d2-984d-ce89af783193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1/3: Filtering outliers...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9651f7fda1084b69820ed56b2eb4fc2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=301)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering done in 3.3 s.\n",
      "\n",
      "Step 2/3: Calculating mask based on pixel statistics...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cabcad91a12749ef92130baca7cb7b44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=301)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask calculation done in 7.3 s.\n",
      "\n",
      "Using a criteria of 2 sigma and 10.0% outliers, 300 pixels was masked.\n",
      "\n",
      "Step 3/3: Calculating standard deviation map...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd5847a58ba040719c4bd4754288a2cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard deviation map calculation done in 4.1 s.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filter_value = 5 # Threshold for outlier rejection - i.e. how many times the average count constitutes an outlier\n",
    "n_sigma = 2 # Confidence interval used in test\n",
    "cut_off_percent = 0.1 #0.1 will mark a pixel as bad if 10% of counts falls outside the n_sigma window\n",
    "\n",
    "# Number of cold and non-existing pixels for pixel-book-keeping\n",
    "neg_px_mask = np.where(avg_img <= 0, 1, 0)\n",
    "num_neg_px = np.sum(neg_px_mask)\n",
    "\n",
    "# Change negative values to np.nan\n",
    "avg_img = np.where(avg_img <= 0, np.nan, avg_img)\n",
    "\n",
    "start = time.perf_counter()\n",
    "print('Step 1/3: Filtering outliers...')\n",
    "progress = IntProgress(min=0, max=images.shape[0])\n",
    "display(progress)\n",
    "for i in range(images.shape[0]):\n",
    "    images[i,:,:] = np.where(images[i,:,:]>filter_value*avg_img, avg_img, images[i,:,:]) \n",
    "    progress.value = i\n",
    "\n",
    "print(f'Filtering done in {time.perf_counter()-start:.1f} s.\\n')\n",
    "\n",
    "mask3d = np.zeros(images.shape)\n",
    "sqrt_avg_img = np.sqrt(avg_img)\n",
    "\n",
    "start = time.perf_counter()\n",
    "print('Step 2/3: Calculating mask based on pixel statistics...')\n",
    "progress = IntProgress(min=0, max=images.shape[0])\n",
    "display(progress)\n",
    "\n",
    "for n in range(images.shape[0]):\n",
    "    dev_from_mean = np.abs(images[n,:,:]-avg_img)  \n",
    "    mask3d[n,:,:] = np.where(n_sigma*sqrt_avg_img > dev_from_mean, 0, 1)\n",
    "    progress.value = n    \n",
    "    \n",
    "# Sum all outliers from the 3D volume to a single frame and check if number of outliers are above the threshold\n",
    "sum_mask = np.sum(mask3d, axis=0) \n",
    "mask = np.where(sum_mask > cut_off_percent*images.shape[0], 1, 0)\n",
    "print(f'Mask calculation done in {time.perf_counter()-start:.1f} s.\\n')\n",
    "\n",
    "# Total number of masked pixels at this step for pixel-book-keeping\n",
    "masked_px = np.sum(mask)\n",
    "\n",
    "print(f'Using a criteria of {n_sigma} sigma and {100*cut_off_percent:.1f}% outliers, {np.sum(mask)-num_neg_px} pixels was masked.\\n')\n",
    "\n",
    "start = time.perf_counter()\n",
    "print('Step 3/3: Calculating standard deviation map...')\n",
    "progress = IntProgress(min=0, max=1) # Include progress bar for consistency\n",
    "display(progress)\n",
    "stdev_img = np.std(images, axis =0)/avg_img\n",
    "progress.value = 1\n",
    "print(f'Standard deviation map calculation done in {time.perf_counter()-start:.1f} s.\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e144bd50-16c2-48c1-ac87-9f1d06b8c256",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Display average data, mask and standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7318ae13-6aeb-42e5-ae64-5efe972699ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ede6f97e088b43ca9151904a1ea9a3e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "ax1 = plt.subplot(1,3,1)\n",
    "ax1.imshow(np.log(avg_img+3), interpolation='Nearest')\n",
    "plt.title('log(average intensity)')\n",
    "ax2 = plt.subplot(1,3,2, sharex=ax1, sharey=ax1)\n",
    "ax2.imshow(mask, interpolation='Nearest')\n",
    "plt.title('mask')\n",
    "ax3 = plt.subplot(1,3,3, sharex=ax1, sharey=ax1)\n",
    "ax3.imshow(stdev_img, vmin=0, vmax=0.25*np.nanmax(stdev_img), interpolation='Nearest')\n",
    "plt.title('\"standard deviation\"')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf9ba98-7203-4714-9f58-504148742fae",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Mask oversensitive pixels based on neighbouring values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46f2d914-712b-4ef9-8d0c-c17cdf23d19e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6b2bd16f3cf4368a2ae8122492ba38b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5118 was estimated to be oversensitive and has been masked.\n"
     ]
    }
   ],
   "source": [
    "neighbour_intensity_ratio = 1.1 # Rejection threshold for ratio of pixel intensities to  average neighbour intensities\n",
    "\n",
    "import scipy.ndimage as ndi\n",
    "\n",
    "# Kernel to find intensity average of neighbouring pixels\n",
    "neighbour_kernel = np.array([[1/8, 1/8, 1/8],\n",
    "                             [1/8,   0, 1/8],\n",
    "                             [1/8, 1/8, 1/8]])\n",
    "\n",
    "# Calc intensity average of neighbouring pixels map and find oversensitive pixels\n",
    "neighbour_ave_img = ndi.correlate(avg_img, neighbour_kernel)\n",
    "mask = np.where(avg_img/neighbour_ave_img > neighbour_intensity_ratio, 1, mask)\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "ax1 = plt.subplot(1,3,1)\n",
    "ax1.imshow(np.log(avg_img+3), interpolation='Nearest')\n",
    "plt.title('log(average intensity)')\n",
    "ax2 = plt.subplot(1,3,2, sharex=ax1, sharey=ax1)\n",
    "ax2.imshow(mask, interpolation='Nearest')\n",
    "plt.title('mask')\n",
    "ax2 = plt.subplot(1,3,3, sharex=ax1, sharey=ax1)\n",
    "ax2.imshow(avg_img/neighbour_ave_img, vmax=1.5, interpolation='Nearest')\n",
    "plt.title('avg_int/avg_neighbour_int')\n",
    "\n",
    "print(f'{np.sum(mask) - masked_px} was estimated to be oversensitive and has been masked.') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65439dcc-2aed-4202-bfe9-92ccba3f2f9b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Diaplay details for single pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afc7e708-1153-43bc-98c0-cb9975c08d59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f77f6b1a40145cc97b3d919ae2a2635",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of outliers: 1\n"
     ]
    }
   ],
   "source": [
    "px_x, px_y = 1414, 1574\n",
    "\n",
    "plt.figure()\n",
    "for i in range(int(n_sigma+1)):\n",
    "    plt.fill_between(np.linspace(0,300, 301), np.mean(images[:,px_y,px_x])+i*sqrt_avg_img[px_y,px_x], \\\n",
    "                 np.mean(images[:,px_y,px_x])-i*sqrt_avg_img[px_y,px_x], color='red', alpha=0.1)\n",
    "plt.plot(images[:,px_y,px_x])\n",
    "plt.title(f'Intensity of px [{px_x}, {px_y}]')\n",
    "plt.ylabel('Intensity / A.U.)')\n",
    "plt.xlabel('Exposure no.')\n",
    "\n",
    "print(f'Number of outliers: {int(sum_mask[px_y, px_x])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1037d471-9c45-43bb-b37b-5355cc255a4f",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Add masked pixels based on geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec65560-7f79-4202-893f-6a9e35cef3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask settings\n",
    "grow_edge_by = 2         # Number of pixels to mask near the edges between modules [2]\n",
    "mask_edge_by = 2         # Number of pixels to mask along the outside edge of the detector [2]\n",
    "grow_cdte_gap_by = 1     # Number of pixels to mask along the middle of each module wher the CdTe pieces leave a gap [1]\n",
    "\n",
    "maskReadout = True      # Mask the edges of the individual readout chips [True]\n",
    "grow_readout_by = 1     # Number of additional pixels to mask around the readout chips [1]\n",
    "\n",
    "#Detector defaults\n",
    "det_size = [1679, 1475]\n",
    "module_size = [195, 487]\n",
    "cdte_gap_pos = int((module_size[1]-1)/2)\n",
    "gap_size = [17, 7]\n",
    "module_no = [8, 3]\n",
    "readout_chip_no = [2, 8]\n",
    "readout_chip_size = [97, 60]\n",
    "# Mask value\n",
    "mask_value = 1\n",
    "    \n",
    "# Create horizontal masks\n",
    "for i in range(module_no[0]-1):\n",
    "    start = (module_size[0]+gap_size[0])*i+module_size[0]-grow_edge_by\n",
    "    end = (module_size[0]+gap_size[0])*(i+1)-1+grow_edge_by\n",
    "    mask[start:end+1, :] = mask_value\n",
    "\n",
    "# Create vertical masks\n",
    "for i in range(module_no[1]-1):\n",
    "    start = (module_size[1]+gap_size[1])*i+module_size[1]-grow_edge_by\n",
    "    end = (module_size[1]+gap_size[1])*(i+1)-1+grow_edge_by\n",
    "    mask[:, start:end+1] = mask_value\n",
    "\n",
    "# Mask mid-module (CdTe) gaps:\n",
    "for i in range(module_no[1]):\n",
    "    start = (module_size[1]+gap_size[1])*i+cdte_gap_pos-grow_cdte_gap_by\n",
    "    end = (module_size[1]+gap_size[1])*i+cdte_gap_pos+grow_cdte_gap_by\n",
    "    mask[:, start:end+1] = mask_value\n",
    "\n",
    "# Mask between readout chips:\n",
    "if maskReadout:\n",
    "    # Create horizontal lines\n",
    "    for i in range(module_no[0]):\n",
    "        corner_module = (module_size[0]+gap_size[0])*i\n",
    "        for j in range(readout_chip_no[0]-1):\n",
    "            start = corner_module+(readout_chip_size[0]+1)*j+readout_chip_size[0]-grow_readout_by\n",
    "            end = corner_module+(readout_chip_size[0]+1)*j+readout_chip_size[0]+grow_readout_by\n",
    "            mask[start:end+1, :] = mask_value\n",
    "    # Create vertical lines\n",
    "    for i in range(module_no[1]):\n",
    "        corner_module = (module_size[1]+gap_size[1])*i\n",
    "        for j in range(readout_chip_no[1]-1):\n",
    "            if j == 3:\n",
    "                pass\n",
    "            else:\n",
    "                start = corner_module+(readout_chip_size[1]+1)*j+readout_chip_size[1]-grow_readout_by\n",
    "                end = corner_module+(readout_chip_size[1]+1)*j+readout_chip_size[1]+grow_readout_by\n",
    "                mask[:, start:end+1] = mask_value\n",
    "\n",
    "# Mask edges:\n",
    "if mask_edge_by > 0:\n",
    "    mask[:, :mask_edge_by] = mask_value\n",
    "    mask[:, -1*mask_edge_by:] = mask_value\n",
    "    mask[:mask_edge_by, :] = mask_value\n",
    "    mask[-1*mask_edge_by:, :] = mask_value\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(mask, interpolation='Nearest') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdc93e4-8637-49b3-b53a-95b425ddbde7",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Save mask for Azint (.npy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8b28af6-0e53-405b-a97b-e9c53b5fcda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_mask = fname.split('raw')[0]+'process/autogenerated_mask.npy'\n",
    "np.save(fname_mask, mask, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16798f78-e0b8-46cf-98bc-58f3982bf1a7",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Save mask for Dioptas (.mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f080fce9-68f8-48a2-8ede-e78d414ae678",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageTk\n",
    "\n",
    "fname_mask = fname.split('raw')[0]+'process/autogenerated.mask'\n",
    "print(fname_mask)\n",
    "\n",
    "im = Image.fromarray(np.asarray(mask, dtype=np.int32))\n",
    "im.save(fname_mask, \"TIFF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cba67a1-28da-45f8-a3c6-860b8bc7731e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HDF5 / Simple Analysis / GPU",
   "language": "python",
   "name": "maxiv-jhub-docker-kernel-hdf5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
