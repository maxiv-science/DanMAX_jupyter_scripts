{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "143e67af-b21a-4a30-9f01-f8b35388f9f5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Integrate AMPIX .h5 files created with the DanMAX AMPIX battery script using pyFAI\n",
    "\n",
    "This notebook can be used to integrate a series of `*.h5` files with `pyFAI` from the master file. The frames in a given entry are averaged before the integration. The script must be run individually for each cell in the whole measurement run. The required inputs are:\n",
    "\n",
    "1 `fname`: Path for `.h5` master file<br>\n",
    "2 `poni`: Path for `.poni`<br>\n",
    "3 `maskPath`: Path for detector mask, e.g. `.npy` format<br>\n",
    "4 `nbins`: Number of bins in the integrated data<br>\n",
    "5 `useQ`: `True`/`False` if true the integration will be done in Q [Ã…^{-1}] - if false the integration is in 2theta [degrees]<br>\n",
    "6 `polarization_factor`: Polarization factor, should be very close to (but slightly lower than) 1. <br>\n",
    "\n",
    "The output will be saved in:\n",
    "`/data/visitors/danmax/PROPOSAL/VISIT/process/pyFAI/SAMPLE/scan-XXXX_pilatus_integrated.h5` i.e. mirroring the location of the raw data. A timestamp file with the real times is also generated and saved in the h5-file and as a\n",
    "`*.text` file. The times correspond approximately to halfway through a timescan on the cell in order to have a single timestamp per timescan as this is the common practice.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c6af9b-73af-4e6b-84a5-1085b0f814c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tifffile\n",
    "import pyFAI\n",
    "import glob\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import re\n",
    "\n",
    "fname = '/data/visitors/danmax/PROPOSAL/VISIT/raw/SAMPLE/battery_X/master.h5'\n",
    "poni = '/data/visitors/danmax/PROPOSAL/VISIT/process/MyPoni.poni'\n",
    "maskPath = '/data/visitors/danmax/PROPOSAL/VISIT/process/MyMask.npy'\n",
    "\n",
    "nbins = 3000\n",
    "polarization_factor=0.99997\n",
    "\n",
    "useQ = True # Use Q/AA^-1 if True. Will use TTH in degrees if False\n",
    "\n",
    "#--------------------------------------------------------\n",
    "\n",
    "#Loading mask and poni to pyFAI\n",
    "ai = pyFAI.load(poni) \n",
    "mask = np.load(maskPath) \n",
    "ai.set_mask(mask)\n",
    "\n",
    "timezone = pytz.timezone('Europe/Stockholm') #The timezone is needed to generate the proper time stamp\n",
    "\n",
    "#Setting up the filename for the integrated data\n",
    "out = fname.split('.')[0]+'_ampix_pilatus_integrated.h5'\n",
    "out = out.replace('raw', 'process/pyFAI')\n",
    "path, _ = os.path.split(out)\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "print('Integrated data will be saved in: {0}'.format(out))\n",
    "new_filename = out.split('.')[0]+'_timestamps.txt'\n",
    "stamplist = []\n",
    "\n",
    "#Generating the file for the integrated data\n",
    "out_fh = h5py.File(out, 'w')\n",
    "\n",
    "#Reading the raw file\n",
    "fh = h5py.File(fname)\n",
    "\n",
    "#Here, we determine how many timescans have been made on the cell based on the number of generated Pilatus files\n",
    "d = fname.split('master')[0]\n",
    "nentry = len(glob.glob(d+'*.h5'))-1\n",
    "\n",
    "#The data structure is set up based on the number of bins chosen and the number of timescans on the cell\n",
    "dset = out_fh.create_dataset('I', shape=(nentry, nbins))\n",
    "\n",
    "if useQ:\n",
    "    print('Integrating in Q[AA-1]')\n",
    "else:\n",
    "    print('Integrating in TTH[Deg]')\n",
    "\n",
    "for ent in range(nentry):\n",
    "    images = fh['/entry'+format(ent+1, '04d')+'/instrument/pilatus/data']\n",
    "    avg_img = np.mean(images, axis=0) #The frames in the given timescan are averaged.\n",
    "    \n",
    "    if useQ:\n",
    "        q, I = ai.integrate1d(avg_img, nbins, unit='q_nm^-1', polarization_factor=polarization_factor, correctSolidAngle=True)\n",
    "        dset[ent] = I\n",
    "        if ent == 0:\n",
    "            out_fh.create_dataset('q', data=q/10) # convert from nm^-1 to AA^-1\n",
    "    else:\n",
    "        tth, I = ai.integrate1d(avg_img, nbins, unit='2th_deg', polarization_factor=polarization_factor, correctSolidAngle=True)\n",
    "        dset[ent] = I\n",
    "        if ent == 0:\n",
    "            out_fh.create_dataset('tth', data=tth)\n",
    "    \n",
    "    timeStampUnix = fh['/entry'+format(ent+1, '04d')+'/measurement/pcap_trigts'][round(len(timeStampsUnix)/2)] #The length of the timescan is determind and the frame halfway through is selected for the timestamp\n",
    "    offsetTZ = timezone.localize(datetime.utcfromtimestamp(timeStampUnix)).utcoffset()\n",
    "    stamp = \"{0:05d}, {1}\\n\".format(ent+1, datetime.utcfromtimestamp(timeStampUnix)+offsetTZ) #The timescan number is saved along with the corresponding date and time\n",
    "    stamplist.append(stamp)\n",
    "    \n",
    "    print('Processing: {0} of {1} - {2:.1f}% complete...'.format(ent+1, nentry, ent/nentry*100), end='\\r')\n",
    "    \n",
    "np.savetxt(new_filename, stamplist, fmt=\"%s\") #The time stamp list is generated and saved in the same folder as the h5 file containing the integrated data\n",
    "    \n",
    "with open(poni, 'r') as poni_file:\n",
    "    print('\\nWriting poni information to file...')\n",
    "    p = out_fh.create_dataset('poni_file', data=poni_file.read()) #The used poni file is saved to the h5 file for future reference\n",
    "\n",
    "print('Writing mask path to file...')\n",
    "m = out_fh.create_dataset('mask', data=mask) #The used mask file is saved to the h5 file for future reference\n",
    "\n",
    "print('Writing time stamp to file...')\n",
    "t = out_fh.create_dataset('timestamp', data=stamplist) #The time stamp list is saved to the h5 file\n",
    "    \n",
    "out_fh.close()\n",
    "print('All done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a88fca1-b178-4c68-a680-d089ebee8512",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HDF5 / Simple Analysis / GPU",
   "language": "python",
   "name": "maxiv-jhub-docker-kernel-hdf5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
